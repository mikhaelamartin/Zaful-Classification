{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-d2875e69b4d8>:34: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "  from collections import Iterable\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import csv\n",
    "import datetime as dt\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import itertools\n",
    "\n",
    "from collections import Iterable\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from nltk.collocations import *\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import random\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score, f1_score,precision_recall_curve,precision_score, accuracy_score\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "#Import svm model\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# numerical_reviews = ['Individual Rating', 'Number of Pictures', 'Height', 'Waist', 'Hips', 'Date (ordinal)', 'Time (numerical)']\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "item_csv = r\"zaful_floral_dresses_latest.csv\"\n",
    "items = pd.read_csv(item_csv)\n",
    "\n",
    "reviews_csv = r\"zaful_reviews_latest.csv\"\n",
    "reviews = pd.read_csv(reviews_csv)\n",
    "\n",
    "# add sku column to reviews\n",
    "reviews = pd.merge(reviews, items[['SKU','Rank']], how='inner', on=['SKU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reviews:  454\n",
      "Number of Items:  519\n",
      "Items without Reviews:  65\n"
     ]
    }
   ],
   "source": [
    "# how many products have reviews?\n",
    "print(\"Total Reviews: \", reviews['SKU'].nunique())\n",
    "print(\"Number of Items: \", items['SKU'].nunique())\n",
    "print(\"Items without Reviews: \", len(items[items['Number of Reviews'].isnull()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         SKU  Individual Rating  Number of Pictures  \\\n",
      "0  461000702                  5                   5   \n",
      "\n",
      "                                             Comment  \\\n",
      "0  It is thin but I’ve bought for holiday so I’m ...   \n",
      "\n",
      "                    Date Stamp        Color/Size  \\\n",
      "0  Aug. 17 2020 at 02:21:14 AM  Color:RED/Size:M   \n",
      "\n",
      "                               Overall Fit  \\\n",
      "0  [<span>Overall Fit: True to Size</span>   \n",
      "\n",
      "                                Height                              Waist  \\\n",
      "0   <span>Height: 170CM \\ 5' 7\"</span>   <span>Waist: 73CM \\ 28.7\"</span>   \n",
      "\n",
      "                               Hips                           Bust  Rank  \n",
      "0   <span>Hips: 87CM \\ 34.3\"</span>   <span>Bust Size: 32C</span>]     1  \n",
      "   Rank        SKU                                        Item Name  \\\n",
      "0     1  461000702  ZAFUL Ditsy Dot Cami Flounce Wrap Dress - Red M   \n",
      "\n",
      "   Shop Price  Recommended Retail Price             Deals  \\\n",
      "0       16.99                     21.43  No viewable deal   \n",
      "\n",
      "                  Available Colors  Overall Rating  Number of Reviews  \\\n",
      "0  Red; BLACK; LIGHT ORANGE; WHITE             5.0              195.0   \n",
      "\n",
      "  True Fit Percentage Too Small Percentage Too Large Percentage  \n",
      "0              89.12%                8.29%                2.59%  \n"
     ]
    }
   ],
   "source": [
    "# what the data looks like\n",
    "print(reviews.head(1))\n",
    "print(items.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviews "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix `Height`, `Waist`, `Hips`, `Bust`', and `Overall Fit` values and strip unnecessary text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_cleaned = reviews.copy()\n",
    "\n",
    "def clean_reviews_whhof(df):\n",
    "    # Fill empty values with np.NaN\n",
    "    df = df.replace('[]', ' ')\n",
    "    # Rename rows - measured in cm (height, waist, hips)\n",
    "    df = df.rename(columns = {'Unnamed: 7': 'Height', 'Unnamed: 8': 'Waist', 'Unnamed: 9': 'Hips', 'Unnamed: 10': 'Bust'}, inplace = False)\n",
    "\n",
    "    # replace nan with NaN\n",
    "    df = df.replace('nan',np.NaN)\n",
    "\n",
    "    # Reorganize hips, waist, overall fit, height, bust columns\n",
    "    for record in range(0,len(df)):\n",
    "        # Bust is in height, rest are missing\n",
    "        if df.iloc[record,6:11].isnull().sum() == 3 and not df['Height'].str.contains(\"Height\").fillna(False)[record] :\n",
    "            df.iloc[record, 7] = df.iloc[record, 6] \n",
    "            df.iloc[record, 6] = np.NaN \n",
    "        # Bust is in waist\n",
    "        if df.iloc[record,6:11].isnull().sum() == 2 and df['Waist'].str.contains(\"Height\").fillna(False)[record]:\n",
    "            bust = df.iloc[record, 8] \n",
    "            df.iloc[record, 10] = bust\n",
    "            df.iloc[record, 8] = np.NaN\n",
    "        if df.iloc[record,6:11].isnull().sum() == 1:\n",
    "            # Overall Fit missing\n",
    "            if not df['Overall Fit'].str.contains(\"Overall Fit\").fillna(False)[record]:\n",
    "                df.iloc[record, 10] = df.iloc[record, 9] \n",
    "                df.iloc[record, 9] = df.iloc[record, 8]\n",
    "                df.iloc[record, 8] = df.iloc[record, 7]\n",
    "                df.iloc[record, 7] = df.iloc[record, 6]\n",
    "                df.iloc[record, 6] = np.NaN\n",
    "            # Height missing\n",
    "            elif not df['Height'].str.contains(\"Height\").fillna(False)[record]:\n",
    "                df.iloc[record, 10] = df.iloc[record, 9] \n",
    "                df.iloc[record, 9] = df.iloc[record, 8]\n",
    "                df.iloc[record, 8] = df.iloc[record, 7]\n",
    "                df.iloc[record, 7] = np.NaN\n",
    "            # Waist missing\n",
    "            elif not df['Waist'].str.contains(\"Waist\").fillna(False)[record]:\n",
    "                df.iloc[record, 10] = df.iloc[record, 9] \n",
    "                df.iloc[record, 9] = df.iloc[record, 8]\n",
    "                df.iloc[record, 8] = np.NaN \n",
    "            # Bust missing\n",
    "            elif not df['Bust'].str.contains(\"Bust\").fillna(False)[record]:\n",
    "                df.iloc[record, 9] = df.iloc[record, 10] \n",
    "                df.iloc[record, 10] = np.NaN \n",
    "            # Hips missing\n",
    "            else:\n",
    "                bust = df.iloc[record, 9] \n",
    "                df.iloc[record, 10] = bust\n",
    "                df.iloc[record, 9] = np.NaN\n",
    "\n",
    "    # Extract only the numbers in centimeters\n",
    "    df['Height'] = df['Height'].str.extract(r'(?<!\\d)(\\d{3})(?!\\d)', expand=False)   \n",
    "    df['Waist'] = df['Waist'].str.extract(r'(?<!\\d)(\\d{2})(?!\\d)', expand=False)  \n",
    "    df['Hips'] = df['Hips'].str.extract(r'(?<!\\d)(\\d{2})(?!\\d)', expand=False)  \n",
    "    df['Bust'] = df['Bust'].str.extract(r'(\\d{2}[a-zA-Z]+)', expand=False)\n",
    "    \n",
    "    # Convert bust sizes to cm\n",
    "    bust_conversion = {\"34C\": 92.5,\n",
    "    \"32C\": 87.5,\n",
    "    \"34D\": 95.5,\n",
    "    \"32D\": 90,\n",
    "    \"34B\": 90,\n",
    "    \"32B\": 85,\n",
    "    \"36C\": 98,\n",
    "    \"32AA\": 76,\n",
    "    \"36AA\": 86,\n",
    "    \"32A\": 82.5,\n",
    "    \"34AA\": 81,\n",
    "    \"36D\": 101,\n",
    "    \"38AA\": 81.5,\n",
    "    \"34A\": 87.5,\n",
    "    \"36B\": 95.5,\n",
    "    \"38C\": 103,\n",
    "    \"36A\": 92.5,\n",
    "    \"38B\": 100.5,\n",
    "    \"38A\": 98,\n",
    "    \"38D\": 105.5}\n",
    "    df['Bust'] = df['Bust'].replace(bust_conversion)\n",
    "\n",
    "    # Replace Overall Fit \n",
    "    # 0 - True to Size\n",
    "    # 1 - Large\n",
    "    # -1 - Small\n",
    "    df['Overall Fit'] = df['Overall Fit'].str.extract(r':(.*)<', expand=False).str.strip().replace({'True to Size', 'Small', 'Large'}, {0, -1, 1})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split `Color/Size` column into 'Color' and 'Size' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate color and size bought by customer into two columns\n",
    "\n",
    "def reviews_clean_color_size(df):\n",
    "    df['Color'] = df['Color/Size'].str.extract(r':(.*)/', expand=False)\n",
    "    df['Size'] = df['Color/Size'].str.extract(r'Size:(.*)', expand=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add and delete columns: Split `Date Stamp` column into `Date`, `Time`, `Time (numerical)`, and `Date (ordinal)`; add `Total Colors` and `Comment Length` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviews_clean_date_time_color_size_comment(df):\n",
    "\n",
    "    # Separate time and date for linear regression purposes\n",
    "    df['Date (ordinal)'] = pd.to_datetime(reviews_cleaned['Date Stamp'].str.extract(r'(.*) at', expand=False)).map(dt.datetime.toordinal)\n",
    "    df['Date'] = pd.to_datetime(reviews_cleaned['Date Stamp'].str.extract(r'(.*) at', expand=False))\n",
    "    df['Time'] = df['Date Stamp'].str.extract(r'at (.*) [a-zA-Z]+', expand=False)\n",
    "\n",
    "    result = []\n",
    "    for i in reviews_cleaned['Time']: \n",
    "        (h, m, s) = i.split(':')\n",
    "        result.append(int(h) * 3600 + int(m) * 60 + int(s))\n",
    "\n",
    "    df['Time (numerical)']  = result\n",
    "\n",
    "    # Delete columns that are no longer needed\n",
    "    df = df.drop(columns=['Color/Size', 'Date Stamp'])\n",
    "\n",
    "    # Number of total colors (including main)\n",
    "    # reviews_cleaned['Total Colors'] = reviews_color_encode.apply(lambda x: len(x))\n",
    "\n",
    "    # Comment Length\n",
    "    df['Comment'] = df.Comment.astype(str)\n",
    "    df['Comment Length'] = df['Comment'].apply(lambda x: len(x))\n",
    "\n",
    "    # change str type to int \n",
    "    df[[\"Height\", \"Waist\",'Hips', 'Bust']] = df[[\"Height\", \"Waist\",'Hips', 'Bust']].apply(pd.to_numeric)\n",
    "    \n",
    "    # drop duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>Individual Rating</th>\n",
       "      <th>Number of Pictures</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Overall Fit</th>\n",
       "      <th>Height</th>\n",
       "      <th>Waist</th>\n",
       "      <th>Hips</th>\n",
       "      <th>Bust</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Color</th>\n",
       "      <th>Size</th>\n",
       "      <th>Date (ordinal)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Time (numerical)</th>\n",
       "      <th>Comment Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>461000702</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>It is thin but I’ve bought for holiday so I’m ...</td>\n",
       "      <td>1</td>\n",
       "      <td>170.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>1</td>\n",
       "      <td>RED</td>\n",
       "      <td>M</td>\n",
       "      <td>737654</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>02:21:14</td>\n",
       "      <td>8474</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SKU  Individual Rating  Number of Pictures  \\\n",
       "0  461000702                  5                   5   \n",
       "\n",
       "                                             Comment Overall Fit  Height  \\\n",
       "0  It is thin but I’ve bought for holiday so I’m ...           1   170.0   \n",
       "\n",
       "   Waist  Hips  Bust  Rank Color Size  Date (ordinal)       Date      Time  \\\n",
       "0   73.0  87.0  87.5     1   RED    M          737654 2020-08-17  02:21:14   \n",
       "\n",
       "   Time (numerical)  Comment Length  \n",
       "0              8474             138  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_cleaned = clean_reviews_whhof(reviews_cleaned)\n",
    "reviews_cleaned = reviews_clean_color_size(reviews_cleaned)\n",
    "reviews_cleaned = reviews_clean_date_time_color_size_comment(reviews_cleaned)\n",
    "reviews_cleaned = reviews_cleaned.drop('index', axis=1)\n",
    "reviews_cleaned.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10736  non-unique comments\n"
     ]
    }
   ],
   "source": [
    "# How many unique reviews\n",
    "print(reviews_cleaned['Comment'].nunique(), \" non-unique comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_cleaned = pd.read_csv(r'items_cleaned_2.csv')\n",
    "reviews_cleaned = pd.read_csv(r'reviews_cleaned_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "def remove_stops(text, stops):\n",
    "    #removes all stop words\n",
    "    words = text.split()\n",
    "    final = []\n",
    "    for word in words:\n",
    "        if word not in stops:\n",
    "            final.append(word)\n",
    "            \n",
    "    #reassembles the text without stop words\n",
    "    final = \" \".join(final)\n",
    "    \n",
    "    #removes all punctuation\n",
    "    final = final.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    #removes all numbers\n",
    "    final = \"\".join([i for i in final if not i.isdigit()])\n",
    "    \n",
    "    #eliminates double white spaces\n",
    "    while \"  \" in final:\n",
    "        final = final.replace(\"  \", \" \")\n",
    "    return (final)\n",
    "\n",
    "def clean_docs(docs):\n",
    "    #gets the NLTK's stopword list for English\n",
    "    stops = stopwords.words(\"english\")\n",
    "    \n",
    "    #empty new list to store the cleaned docs\n",
    "    final = []\n",
    "    \n",
    "    #iterate over all docs and cleans them to be a\n",
    "    #single sentence with no unwanted words\n",
    "    for doc in docs:\n",
    "        clean_doc = remove_stops(doc, stops)\n",
    "        final.append(clean_doc)\n",
    "    \n",
    "    return (final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = clean_docs(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = clean_docs(reviews_cleaned[reviews_cleaned['Comment'].notna()]['Comment']\n",
    "vectorizer = CountVectorizer(min_df=.01,ngram_range=(1,3),max_df=.8,stop_words='english'))\n",
    "X1 = vectorizer.fit_transform(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = (vectorizer.get_feature_names())\n",
    "print(\"\\n\\nFeatures : \\n\", features)\n",
    "print(len(features))\n",
    "print(\"\\n\\nX1 : \\n\", X1.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
